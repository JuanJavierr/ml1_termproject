{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573971d0-d848-4004-8005-6821b3336893",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa03a88b-209d-4bb2-870b-bfb37563980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from modules.utils import build_dataset, tune_logistic_regression, tune_svm, tune_mlp, evaluate\n",
    "from modules.autoencoder import AUTOENCODER\n",
    "from modules.classifier import CLASSIFIER\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3996b37-8d00-4dc1-8870-3a511a735305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fd83b-ab0a-4c11-936f-b80eb2ba4ea3",
   "metadata": {},
   "source": [
    "# PROJECT SPECIFIC IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6001d-80eb-449c-9845-7310b06a3949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/xavier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from modules.preprocess import *\n",
    "from modules.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94aadc4-160c-4bcd-8ad4-06fbb597d6de",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c5f7d9-a096-46ec-ad87-9a199398169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(path=\"lapresse_crawler/output.json\", num_samples=5000, rnd_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d0392-6bc2-479f-bbbf-32ca21a907a6",
   "metadata": {},
   "source": [
    "# PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6db7483-d587-41c0-8d76-1b007103318d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–‰                                                                                                                                                                           | 22/4159 [00:03<09:39,  7.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtext_edit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrp_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrm_newline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrm_punctuation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mrm_stop_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlowercase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlemmatize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhtml_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_entities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/Xavier/Desktop/ml1_termproject/modules/preprocess.py:43\u001b[0m, in \u001b[0;36mtext_edit\u001b[0;34m(dataset, grp_num, rm_newline, rm_punctuation, rm_stop_words, lowercase, lemmatize, html_, convert_entities, expand)\u001b[0m\n\u001b[1;32m     40\u001b[0m     text_ \u001b[38;5;241m=\u001b[39m expand_contractions(text_)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_entities:\n\u001b[0;32m---> 43\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39ments:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ent\u001b[38;5;241m.\u001b[39mlabel_ \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPER\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/spacy/language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcomponent_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/layers/with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_list_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/layers/with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[1;32m     76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[0;32m---> 77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[1;32m     80\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/layers/expand_window.py:22\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _expand_window_ragged(model, X)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_expand_window_floats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/thinc/layers/expand_window.py:30\u001b[0m, in \u001b[0;36m_expand_window_floats\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     28\u001b[0m nW \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq2col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = text_edit(dataset, grp_num=True, rm_newline=True, rm_punctuation=True,\n",
    "              rm_stop_words=True, lowercase=True, lemmatize=True, html_=True, convert_entities=True, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c6730b5-5dc2-4dc0-a1ef-494b83932ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x['text'] for x in dataset.values() if x['section_1'] in ['actualites', 'international', 'sports', 'arts', 'affaires', 'debats']]\n",
    "Y = [x['section_label'] for x in dataset.values() if x['section_1'] in ['actualites', 'international', 'sports', 'arts', 'affaires', 'debats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49f3b0-5dde-44a7-834f-fc89f65c1e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64a44e-dc59-45ce-9ee5-c6674a5af8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7bee805-3401-4027-bb50-e3c65239eb70",
   "metadata": {},
   "source": [
    "# TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9e256e-21f6-46c5-9b8a-2f74282fa4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
    "#X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d6ac6-1f4c-4d51-aa42-0f1b7ca02175",
   "metadata": {},
   "source": [
    "# VECTORIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8829ca-e0ba-408a-8768-9fc18a37f28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/anaconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, min_df=0.01, max_df=0.99)\n",
    "tfidf_train = vectorizer.fit_transform(X_train)\n",
    "tfidf_test =  vectorizer.transform(X_test)\n",
    "#tfidf_valid =  vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "059af351-4504-4062-b82d-63f91ae49a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2beb248-8306-479e-a65b-81e015f9185a",
   "metadata": {},
   "source": [
    "# DEFINE MODEL, OPTIMIZER, LOSS_FCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee2a3562-8ee8-499b-b3a3-b28360244a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = AUTOENCODER().to(device)\n",
    "optimizer = optim.Adam(auto.parameters(), lr = 0.01)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab59fb7-4d9d-46e6-9164-f4ebae6a1831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32de50c4-db0e-4a54-915a-b4b198f4122c",
   "metadata": {},
   "source": [
    "# TRAIN AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e9ddec-06fa-4c2c-88b9-b7ad2cccc475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for epoch 0:\n",
      "Mean train loss for epoch: 0.8053089850827267\n",
      "Mean test loss for epoch: 0.012556259706616401\n",
      "Model saved at epoch 0 with test loss 0.012556259706616401\n",
      "Results for epoch 1:\n",
      "Mean train loss for epoch: 0.5094923675060272\n",
      "Mean test loss for epoch: 0.013460292108356952\n",
      "Results for epoch 2:\n",
      "Mean train loss for epoch: 0.3008909209778434\n",
      "Mean test loss for epoch: 0.007403052691370249\n",
      "Model saved at epoch 2 with test loss 0.007403052691370249\n",
      "Results for epoch 3:\n",
      "Mean train loss for epoch: 0.16521850463591123\n",
      "Mean test loss for epoch: 0.011559158749878406\n",
      "Results for epoch 4:\n",
      "Mean train loss for epoch: 0.0839757911468807\n",
      "Mean test loss for epoch: 0.02278509959578514\n",
      "Results for epoch 5:\n",
      "Mean train loss for epoch: 0.0392814210959171\n",
      "Mean test loss for epoch: 0.020283612981438638\n",
      "Results for epoch 6:\n",
      "Mean train loss for epoch: 0.01681358631896345\n",
      "Mean test loss for epoch: 0.009883162565529346\n",
      "Results for epoch 7:\n",
      "Mean train loss for epoch: 0.006549991348660306\n",
      "Mean test loss for epoch: 0.0037259158678352835\n",
      "Model saved at epoch 7 with test loss 0.0037259158678352835\n",
      "Results for epoch 8:\n",
      "Mean train loss for epoch: 0.002309528050797158\n",
      "Mean test loss for epoch: 0.0012322479858994484\n",
      "Model saved at epoch 8 with test loss 0.0012322479858994484\n",
      "Results for epoch 9:\n",
      "Mean train loss for epoch: 0.0007333231317859731\n",
      "Mean test loss for epoch: 0.00036475107772275804\n",
      "Model saved at epoch 9 with test loss 0.00036475107772275804\n"
     ]
    }
   ],
   "source": [
    "tfidf_train_dense_tensor = torch.unsqueeze(torch.tensor(tfidf_train.toarray(), dtype=torch.float32), dim=1).to(device)\n",
    "tfidf_test_dense_tensor = torch.unsqueeze(torch.tensor(tfidf_test.toarray(), dtype=torch.float32), dim=1).to(device)\n",
    "\n",
    "batch_size = 8\n",
    "dataset = TensorDataset(tfidf_train_dense_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(tfidf_test_dense_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "epochs = 10  \n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for batch in dataloader:\n",
    "        X, = batch\n",
    "        X = X.to(device)\n",
    "        auto.train()\n",
    "        auto_out = auto(X)\n",
    "        auto.zero_grad()\n",
    "        loss = loss_function(auto_out, X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "        train_losses.append(loss_value)\n",
    "    \n",
    "    for batch in test_dataloader:\n",
    "        X, = batch  \n",
    "        X = X.to(device)\n",
    "        auto.eval()\n",
    "        auto_out = auto(X)\n",
    "        loss = loss_function(auto_out, X)\n",
    "        loss_value = loss.item()\n",
    "        test_losses.append(loss_value)\n",
    "\n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "    print(f'Results for epoch {epoch}:')\n",
    "    print(f'Mean train loss for epoch: {np.mean(train_losses)}')\n",
    "    print(f'Mean test loss for epoch: {mean_test_loss}')\n",
    "\n",
    "    if mean_test_loss < best_test_loss:\n",
    "        best_test_loss = mean_test_loss\n",
    "        torch.save(auto.state_dict(), 'model_best.pt')  # Save the model\n",
    "        print(f'Model saved at epoch {epoch} with test loss {mean_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80eb788e-9a95-494b-b63f-3a1723fc308b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "auto = AUTOENCODER().to(device)  \n",
    "state_dict = torch.load('model_best.pt', map_location=device)  \n",
    "auto.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b07bd-7e67-4cb5-96a2-c58c9abfb9ea",
   "metadata": {},
   "source": [
    "# PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86048b59-0856-4e0c-bb49-cc57c025707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_dense_tensor = torch.unsqueeze(torch.tensor(tfidf_train.toarray(), dtype=torch.float32), dim=1).to(device)  \n",
    "tfidf_test_dense_tensor = torch.unsqueeze(torch.tensor(tfidf_test.toarray(), dtype=torch.float32), dim=1).to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45beceb-fd02-4f03-be2e-9fd4bd176044",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.eval()\n",
    "autoencoder_train_tensor = []\n",
    "for tensor_ in tfidf_train_dense_tensor:\n",
    "    encode_output = auto.encode(torch.unsqueeze(tensor_, dim=1))\n",
    "    autoencoder_train_tensor.append(encode_output)\n",
    "\n",
    "autoencoder_train_tensor = torch.stack(autoencoder_train_tensor, dim=1)\n",
    "shape_ = autoencoder_train_tensor.shape[1:]\n",
    "autoencoder_train_tensor = autoencoder_train_tensor.view(shape_[0],shape_[1],shape_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ecc9f-f8f2-4f60-8902-b29856526206",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_test_tensor = []\n",
    "for tensor_ in tfidf_test_dense_tensor:\n",
    "    encode_output = auto.encode(torch.unsqueeze(tensor_, dim=1))\n",
    "    autoencoder_test_tensor.append(encode_output)\n",
    "\n",
    "autoencoder_test_tensor = torch.stack(autoencoder_test_tensor, dim=1)\n",
    "shape_ = autoencoder_test_tensor.shape[1:]\n",
    "autoencoder_test_tensor = autoencoder_test_tensor.view(shape_[0],shape_[1],shape_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f413d-7a17-4493-b48c-4c8f1e24e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(autoencoder_train_tensor, open('autoencoder_train_tensor.pkl', 'wb'))\n",
    "pickle.dump(autoencoder_test_tensor, open('autoencoder_test_tensor.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cad301-deaa-4cee-a4fd-e477c6abbd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train_tensor = pickle.load(open('autoencoder_train_tensor.pkl', 'rb'))\n",
    "autoencoder_test_tensor = pickle.load(open('autoencoder_test_tensor.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19347711-5efe-4ecf-8bdb-4a56b2701052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce240b6-450b-407b-b190-6554203d6cc7",
   "metadata": {},
   "source": [
    "# DEFINE MODEL, OPTIMIZER, LOSS_FCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c153d74-5421-4f85-ae46-6c44221cf6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CLASSIFIER(k=5, num_class=4).to(device)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr = 0.01)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748f809-b932-46b1-b690-1e6a37e56219",
   "metadata": {},
   "source": [
    "# TRAIN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee2303-fe7d-4e61-aa01-1beb3bbef2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "\n",
    "dataset = TensorDataset(autoencoder_train_tensor, torch.tensor(Y_train,dtype=torch.long))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(autoencoder_test_tensor, torch.tensor(Y_test,dtype=torch.long))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for X, Y in dataloader:  \n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        classifier.train()\n",
    "        pred_out = classifier(X)\n",
    "        classifier.zero_grad()\n",
    "        loss = loss_function(pred_out.view(len(X),-1), Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "        train_losses.append(loss_value)\n",
    "    \n",
    "    for X, Y in test_dataloader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        classifier.eval()\n",
    "        pred_out = classifier(X)\n",
    "        loss = loss_function(pred_out.view(len(X),-1), Y)\n",
    "        loss_value = loss.item()\n",
    "        test_losses.append(loss_value)\n",
    "        \n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "    print(f'Results for epoch {epoch}:')\n",
    "    print(f'Mean train loss for epoch: {np.mean(train_losses)}')\n",
    "    print(f'Mean test loss for epoch: {mean_test_loss}')\n",
    "\n",
    "    if mean_test_loss < best_test_loss:\n",
    "        best_test_loss = mean_test_loss\n",
    "        torch.save(auto.state_dict(), 'model_best.pt') \n",
    "        print(f'Model saved at epoch {epoch} with test loss {mean_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d781c9ba-338c-41c9-af89-b91ad196cea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ed813-b62b-4bb8-8716-1a71e0366511",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "pred_outputs = []\n",
    "for tensor_ in autoencoder_test_tensor:\n",
    "    encode_output = classifier(torch.unsqueeze(tensor_, dim=0))\n",
    "    pred_class = np.argmax(encode_output.detach().numpy())\n",
    "    pred_outputs.append(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4345a-62fa-417f-ba3c-e256bce9d237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b14b2-6aa7-4bda-85d3-13947b1f1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(Y_test, pred_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abda8f-4027-4a7f-9688-26b064f6d99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
