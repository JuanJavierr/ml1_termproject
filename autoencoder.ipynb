{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573971d0-d848-4004-8005-6821b3336893",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa03a88b-209d-4bb2-870b-bfb37563980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from modules.utils import build_dataset, tune_logistic_regression, tune_svm, tune_mlp, evaluate\n",
    "from modules.autoencoder import AUTOENCODER\n",
    "from modules.classifier import CLASSIFIER\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3996b37-8d00-4dc1-8870-3a511a735305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fd83b-ab0a-4c11-936f-b80eb2ba4ea3",
   "metadata": {},
   "source": [
    "# PROJECT SPECIFIC IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d6001d-80eb-449c-9845-7310b06a3949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/xavier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from modules.preprocess import *\n",
    "from modules.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94aadc4-160c-4bcd-8ad4-06fbb597d6de",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c5f7d9-a096-46ec-ad87-9a199398169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(path=\"lapresse_crawler/output.json\", num_samples=1000, rnd_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d0392-6bc2-479f-bbbf-32ca21a907a6",
   "metadata": {},
   "source": [
    "# PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6db7483-d587-41c0-8d76-1b007103318d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:55<00:00,  8.64it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = text_edit(dataset, grp_num=True, rm_newline=True, rm_punctuation=True,\n",
    "              rm_stop_words=True, lowercase=True, lemmatize=True, html_=True, convert_entities=True, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c6730b5-5dc2-4dc0-a1ef-494b83932ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x['text'] for x in dataset.values() if x['section_1'] in ['actualites', 'international', 'sports', 'arts', 'affaires', 'debats']]\n",
    "Y = [x['section_label'] for x in dataset.values() if x['section_1'] in ['actualites', 'international', 'sports', 'arts', 'affaires', 'debats']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bee805-3401-4027-bb50-e3c65239eb70",
   "metadata": {},
   "source": [
    "# TRAIN/TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9e256e-21f6-46c5-9b8a-2f74282fa4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
    "#X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d6ac6-1f4c-4d51-aa42-0f1b7ca02175",
   "metadata": {},
   "source": [
    "# VECTORIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8829ca-e0ba-408a-8768-9fc18a37f28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/anaconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, min_df=0.01, max_df=0.99)\n",
    "tfidf_train = vectorizer.fit_transform(X_train)\n",
    "tfidf_test =  vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059af351-4504-4062-b82d-63f91ae49a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2beb248-8306-479e-a65b-81e015f9185a",
   "metadata": {},
   "source": [
    "# DEFINE MODEL, OPTIMIZER, LOSS_FCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a3562-8ee8-499b-b3a3-b28360244a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = AUTOENCODER().to(device)\n",
    "optimizer = optim.Adam(auto.parameters(), lr = 0.01)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab59fb7-4d9d-46e6-9164-f4ebae6a1831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32de50c4-db0e-4a54-915a-b4b198f4122c",
   "metadata": {},
   "source": [
    "# TRAIN AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9ddec-06fa-4c2c-88b9-b7ad2cccc475",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_dense_tensor = torch.unsqueeze(torch.tensor(tfidf_train.toarray(), dtype=torch.float32), dim=1).to(device)\n",
    "tfidf_test_dense_tensor = torch.unsqueeze(torch.tensor(tfidf_test.toarray(), dtype=torch.float32), dim=1).to(device)\n",
    "\n",
    "batch_size = 8\n",
    "dataset = TensorDataset(tfidf_train_dense_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(tfidf_test_dense_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "epochs = 10  \n",
    "best_test_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for batch in dataloader:\n",
    "        X, = batch\n",
    "        X = X.to(device)\n",
    "        auto.train()\n",
    "        auto_out = auto(X)\n",
    "        auto.zero_grad()\n",
    "        loss = loss_function(auto_out, X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "        train_losses.append(loss_value)\n",
    "    \n",
    "    for batch in test_dataloader:\n",
    "        X, = batch  \n",
    "        X = X.to(device)\n",
    "        auto.eval()\n",
    "        auto_out = auto(X)\n",
    "        loss = loss_function(auto_out, X)\n",
    "        loss_value = loss.item()\n",
    "        test_losses.append(loss_value)\n",
    "\n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "    print(f'Results for epoch {epoch}:')\n",
    "    print(f'Mean train loss for epoch: {np.mean(train_losses)}')\n",
    "    print(f'Mean test loss for epoch: {mean_test_loss}')\n",
    "\n",
    "    if mean_test_loss < best_test_loss:\n",
    "        best_test_loss = mean_test_loss\n",
    "        torch.save(auto.state_dict(), 'model_best.pt')  # Save the model\n",
    "        print(f'Model saved at epoch {epoch} with test loss {mean_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb788e-9a95-494b-b63f-3a1723fc308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "auto = AUTOENCODER().to(device)  \n",
    "state_dict = torch.load('model_best.pt', map_location=device)  \n",
    "auto.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b07bd-7e67-4cb5-96a2-c58c9abfb9ea",
   "metadata": {},
   "source": [
    "# PREDICTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86048b59-0856-4e0c-bb49-cc57c025707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_dense_tensor = torch.unsqueeze(torch.tensor(tfidf_train.toarray(), dtype=torch.float32), dim=1).to(device)  \n",
    "tfidf_test_dense_tensor = torch.unsqueeze(torch.tensor(tfidf_test.toarray(), dtype=torch.float32), dim=1).to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45beceb-fd02-4f03-be2e-9fd4bd176044",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.eval()\n",
    "autoencoder_train_tensor = []\n",
    "for tensor_ in tfidf_train_dense_tensor:\n",
    "    encode_output = auto.encode(torch.unsqueeze(tensor_, dim=1))\n",
    "    autoencoder_train_tensor.append(encode_output.detach())\n",
    "\n",
    "autoencoder_train_tensor = torch.stack(autoencoder_train_tensor, dim=1)\n",
    "shape_ = autoencoder_train_tensor.shape[1:]\n",
    "autoencoder_train_tensor = autoencoder_train_tensor.view(shape_[0],shape_[1],shape_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ecc9f-f8f2-4f60-8902-b29856526206",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_test_tensor = []\n",
    "for tensor_ in tfidf_test_dense_tensor:\n",
    "    encode_output = auto.encode(torch.unsqueeze(tensor_, dim=1))\n",
    "    autoencoder_test_tensor.append(encode_output.detach())\n",
    "\n",
    "autoencoder_test_tensor = torch.stack(autoencoder_test_tensor, dim=1)\n",
    "shape_ = autoencoder_test_tensor.shape[1:]\n",
    "autoencoder_test_tensor = autoencoder_test_tensor.view(shape_[0],shape_[1],shape_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a907608-1311-4b36-8ba8-3ddb2387157c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce240b6-450b-407b-b190-6554203d6cc7",
   "metadata": {},
   "source": [
    "# DEFINE MODEL, OPTIMIZER, LOSS_FCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c153d74-5421-4f85-ae46-6c44221cf6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CLASSIFIER(k=5, num_class=len(set(Y))).to(device)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr = 0.01)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748f809-b932-46b1-b690-1e6a37e56219",
   "metadata": {},
   "source": [
    "# TRAIN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee2303-fe7d-4e61-aa01-1beb3bbef2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "\n",
    "dataset = TensorDataset(autoencoder_train_tensor, torch.tensor(Y_train,dtype=torch.long))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(autoencoder_test_tensor, torch.tensor(Y_test,dtype=torch.long))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for X, Y in dataloader:  \n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        classifier.train()\n",
    "        pred_out = classifier(X)\n",
    "        classifier.zero_grad()\n",
    "        loss = loss_function(pred_out.view(len(X),-1), Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "        train_losses.append(loss_value)\n",
    "    \n",
    "    for X, Y in test_dataloader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        classifier.eval()\n",
    "        pred_out = classifier(X)\n",
    "        loss = loss_function(pred_out.view(len(X),-1), Y)\n",
    "        loss_value = loss.item()\n",
    "        test_losses.append(loss_value)\n",
    "        \n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "    print(f'Results for epoch {epoch}:')\n",
    "    print(f'Mean train loss for epoch: {np.mean(train_losses)}')\n",
    "    print(f'Mean test loss for epoch: {mean_test_loss}')\n",
    "\n",
    "    if mean_test_loss < best_test_loss:\n",
    "        best_test_loss = mean_test_loss\n",
    "        torch.save(auto.state_dict(), 'model_best.pt') \n",
    "        print(f'Model saved at epoch {epoch} with test loss {mean_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a008466-6683-44b9-bf15-d9db84a1e6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ed813-b62b-4bb8-8716-1a71e0366511",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.eval()\n",
    "pred_outputs = []\n",
    "for tensor_ in autoencoder_test_tensor:\n",
    "    encode_output = classifier(torch.unsqueeze(tensor_, dim=0))\n",
    "    pred_class = np.argmax(encode_output.detach().numpy())\n",
    "    pred_outputs.append(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe08db-9546-4272-bda9-02f25d51797b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b14b2-6aa7-4bda-85d3-13947b1f1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(Y_test, pred_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abda8f-4027-4a7f-9688-26b064f6d99f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
