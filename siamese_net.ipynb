{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c6d6a9-7580-45da-a1c6-6240827f38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from modules.preprocess import *\n",
    "from modules.utils import build_dataset, text_to_word2vec, evaluate\n",
    "from modules.rnn_model import TextRNN\n",
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6bd0b-52ec-4bce-97d0-0678e98a5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense, Dropout, Flatten, Lambda, Input, Conv1D, AveragePooling1D, MaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1c3a96-0854-44c1-99a6-7603247b9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(path=\"lapresse_crawler\", num_samples=100, rnd_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d8a00-e94e-4bba-b034-5bd9e47d4679",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = text_edit(dataset, grp_num=False, rm_newline=True, rm_punctuation=True,\n",
    "              rm_stop_words=False, lowercase=True, lemmatize=False, html_=True, convert_entities=False, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c751c-b99c-48f6-9c07-591908af0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x['text'] for x in dataset.values() if x['section_1'] in ['actualites', 'sports', 'affaires', 'arts', 'international']]\n",
    "Y = [x['section_label'] for x in dataset.values() if x['section_1'] in ['actualites', 'sports', 'affaires', 'arts', 'international']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72172c-ead1-4746-8b91-5327c81275a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26f548-f830-4d9e-bbdc-8b2216234bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27c9b8-a6ab-45b2-9045-d4eed8bd3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'fasttext-wiki-news-subwords-300'  \n",
    "word2vec_model = api.load(model_name)\n",
    "text = \"Ceci est un texte exemple\"\n",
    "vector = text_to_word2vec(text, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35669b-98a7-466a-8fb1-8e63df4f8b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.stack([torch.tensor(text_to_word2vec(x, word2vec_model), dtype=torch.float32).view(-1,1) for x in X_train], dim=0)\n",
    "X_test = torch.stack([torch.tensor(text_to_word2vec(x, word2vec_model), dtype=torch.float32).view(-1,1) for x in X_test], dim=0)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717cc3a-583a-4d46-a19e-eb3de19b38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_list = list(zip(X_train, Y_train))\n",
    "pairs = []\n",
    "labels = []\n",
    "num_pairs = 10\n",
    "for _ in range(num_pairs):\n",
    "    sample1, sample2 = random.sample(zipped_list, 2)\n",
    "    pairs.append([sample1[0], sample2[0]])\n",
    "    if sample1[1] == sample2[1]:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0) \n",
    "pairs = np.array(pairs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19784176-83a1-4218-9dd5-4d11079b8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_net_1D(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv1D(32, 3, activation='relu')(input)  \n",
    "    x = AveragePooling1D(pool_size=2)(x)\n",
    "    x = Conv1D(64, 3, activation='tanh')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='tanh')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='tanh')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='tanh')(x)\n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbbcea-d22a-4dee-90a3-9067d140b565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_network  = create_base_net_1D((300,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651c032-9bd4-4859-8dcb-844f2218c476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c065146-a0b5-4c65-933f-ed535eb7f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_dis(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee42831d-e3c7-4f7b-a8c4-e623ef25c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100c09d-d5c5-41f7-95a4-85dae49050e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    square_pred = tf.square(y_pred)\n",
    "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc6d40-359e-4cb1-8d8b-f9cc33fb59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653dfb4-540e-435e-b19e-46db576efcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    pred = tf.cast(y_pred < 0.5, y_true.dtype)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_true, pred), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ed734-4088-4c94-bd58-2068ec7d0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=(300,1))\n",
    "input_b = Input(shape=(300,1))\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclid_dis,output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9dae2-555e-49aa-b569-02aa4c55a149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219ea18-7b12-482c-b7c1-a16f41bb1d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85035d5e-dcfb-4284-863b-18aba25eca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "model.fit([pairs[:, 0], pairs[:, 1]], labels,\n",
    "          batch_size=2,\n",
    "          epochs=epochs,\n",
    "          validation_data=([pairs[:, 0], pairs[:, 1]], labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58051d-445d-4ab7-9f0c-cdcaa417779e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ba17f-de5a-46af-9a08-42d544614b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
